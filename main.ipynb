{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Problem Statement \n",
    "\n",
    "Submission deadline: Sunday, May 19, 23:59.\n",
    "\n",
    "## General description:\n",
    "\n",
    "The overall task of Project 1 is to program the four methods for unconstrained optimization: steepest descent (SD), Newton method (NM), a conjugate gradient method (CG) and a quasi-Newton method (QN).\n",
    "\n",
    "In the second phase, you can get altogether 40 points plus 10 bonus points by solving/implementing the following tasks and running the tests specified later:\n",
    "\n",
    "1. Newton method with Hessian modification (5 points): see Section 3.4 of the Nocedal-Wright book - you can choose one of the suggested strategies.\n",
    "2. linear CG ( 5 points).\n",
    "3. nonlinear CG $(\\mathbf{5}+\\mathbf{5}=\\mathbf{1 0}$ points): the Fletcher-Reevers method (F-R) and the Polak-Ribiere method (P-R).\n",
    "4. QN methods ( $\\mathbf{5}+\\mathbf{5}=\\mathbf{1 0}$ points $+\\mathbf{5}$ bonus points): the BFGS method (5 points) and the SR1 method with line-search (5 points). Additionally, 5 bonus points can be obtained for the SR1 method within the trust-region framework (Chapter 4 of the N-W book), see Algorithm 6.2 of the N-W book.\n",
    "5. derivatives approximation ( $5+5=\\mathbf{1 0}$ points): what if the user only provides the objective function in a way that we can evaluate it at any point, but there is no formula defining the function and we do not know the derivatives? In Section 8.1 (which we will not cover during the lectures), you can find the methods for approximating the gradient (5 points) and the Hessian (5 points) of a function, using only its function values.\n",
    "6. outperforming the $\\mathbf{N M}$ with a $\\mathbf{Q N}(\\mathbf{3}+\\mathbf{2}=\\mathbf{5}$ bonus points): 3 bonus points will be awarded if you can find a problem, for which the Newton method finds a solution, but it is slower than one of the quasi-Newton methods (simply compare the time each method needs to reach a solution). Careful, while computing the next iterate of the Newton method, do not compute the inverse matrix! Solve the linear system instead. If it helps, you might compare the versions of NM and QN that do not work with explicitly given derivatives and compute the approximations (see above). Additional 2 points will be given, however, if you can do it using explicit derivatives.\n",
    "\n",
    "## Testing/problems to solve:\n",
    "\n",
    "Consider the following two functions:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text { (Rosenbrock function) } f(x)=100\\left(x_{2}-x_{1}^{2}\\right)^{2}+\\left(1-x_{1}\\right)^{2} \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "with 3 different starting points $x_{0}$ :\n",
    "\n",
    "$$\n",
    "(1.2,1.2), \\quad(-1.2,1) \\quad(0.2,0.8)\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{equation}\n",
    "f(x)=150\\left(x_{1} x_{2}\\right)^{2}+\\left(0.5 x_{1}+2 x_{2}-2\\right)^{2} \\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "with 3 different starting points $x_{0}$ :\n",
    "\n",
    "$$\n",
    "(-0.2,1.2), \\quad(3.8,0.1), \\quad(1.9,0.6)\n",
    "$$\n",
    "\n",
    "Thus, there are altogether 6 \"problems\" to solve (2 functions with 3 starting points). Moreover, there are altogether 12 different \"methods\" to try: the standard NM (mainly for comparison purposes) and the NM with Hessian modification, 2 (nonlinear) CG methods, 2 QN methods, and, moreover, each of these 6 methods should be used both with exact derivatives and with approximated derivatives. This results into $6 \\cdot 12=72$ runs.\n",
    "\n",
    "For the line search, use the backtracking algorithm (Algorithm 3.1 in the Nocedal-Wright book). For the stopping criterion, use simply $\\left\\|\\nabla f\\left(x_{k}\\right)\\right\\| \\leq 10^{-6}$. If you have problems reaching this accuracy with some method, you can use a lower accuracy (e.g. $10^{-5}$ or $10^{-4}$ ) or another reasonable stopping criterion (it is up to you to decide what might be a reasonable stopping criterion).\n",
    "\n",
    "Additional 12 runs should be made in case you choose to do the bonus SR1 method within the trust-region framework. Similarly, relevant additional runs should be made if you choose to do the bonus of outperforming the $\\mathrm{NM}$ with a $\\mathrm{QN}$.\n",
    "\n",
    "Finally, to test the linear CG, additional 10 runs should be made for the Hilbert matrix from the first phase of the project (part (iii)) - solve these 5 problems with linear CG as well as with the standard SD again for comparison. Here, however, use the exact line-search!\n",
    "\n",
    "Note that, unlike in the first phase, it is not necessarily a problem if a method does not reach the solution. If you encounter problems, you should try to understand whether it means there is an error in your code (in which case you should correct it) or whether that particular method should not be expected to converge in that particular situation.\n",
    "\n",
    "## What should your submission contain?\n",
    "\n",
    "All the files containing the codes and a report.\n",
    "\n",
    "In the beginning of the report, state clearly which of the tasks 1. - 6. you have implemented. Then, print all the runs you performed. After each run, provide a short summary with number of iterations, final iterate $x_{k}$, the size $\\left\\|\\nabla f\\left(x_{k}\\right)\\right\\|$, and the distance to the solution. For function (2) there are 2 global minimizers with the minimal value 0 - it should be easy for you to identify them.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c799224a7a5b00cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3bec6379edd94f54"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
