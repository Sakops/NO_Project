{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task 1: Newton Hessian</h1>\n",
    "<h3>Rosenbrock Function</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x_{0},x_{1})=100 \\left( x_{1} - x_{0}^{2} \\right)^{2} + \\left( 1 - x_{0} \\right)^{2}$$\n",
    "$$\\nabla f(x_{0},x_{1})=[-400x_{0} \\left( x_{1} - x_{0}^{2} \\right) - 2 \\left( 1 - x_{0} \\right), \\quad 200 \\left( x_{1} - x_{0}^{2} \\right)]^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Implementing modified Newton method with eigenvalue modification\n",
      "\n",
      "Run 1:\n",
      "Iteration 1: x = [1.19591837 1.43020408], ||grad|| = 125.16932531574977, Distance to solution: 0.47271509233076564\n",
      "Iteration 2: x = [1.10252241 1.20682417], ||grad|| = 0.3998200870053441, Distance to solution: 0.2308399464578291\n",
      "Iteration 3: x = [1.0651913  1.13323889], ||grad|| = 4.4156957287332945, Distance to solution: 0.14833241618491672\n",
      "Iteration 4: x = [1.01420971 1.02602221], ||grad|| = 0.7759545183917276, Distance to solution: 0.02964914027637089\n",
      "Iteration 5: x = [1.00486014 1.00965648], ||grad|| = 1.2011506358586848, Distance to solution: 0.010810574958239458\n",
      "Iteration 6: x = [1.00008351 1.00014421], ||grad|| = 0.04814265063775351, Distance to solution: 0.00016664385558154938\n",
      "Iteration 7: x = [1.00000038 1.00000075], ||grad|| = 0.01035404059954795, Distance to solution: 8.420582784010321e-07\n",
      "Iteration 8: x = [1. 1.], ||grad|| = 3.7843401551172776e-06, Distance to solution: 1.0455400474096064e-12\n",
      "\n",
      "Summary - Run 1:\n",
      "Number of iterations: 9\n",
      "Final iterate x_k: [1. 1.]\n",
      "The size ||\n",
      "abla f(x_k)||: 0.0\n",
      "The distance to the solution: 0.0\n",
      "\n",
      "Run 2:\n",
      "Iteration 1: x = [-1.1752809   1.38067416], ||grad|| = 232.86768775422664, Distance to solution: 2.208338697540567\n",
      "Iteration 2: x = [-0.91343237  0.76526556], ||grad|| = 4.639426214066757, Distance to solution: 1.9277768816864183\n",
      "Iteration 3: x = [-0.78430893  0.59846763], ||grad|| = 32.188727358206386, Distance to solution: 1.8289304508565836\n",
      "Iteration 4: x = [-0.56554344  0.26416883], ||grad|| = 9.409933652774024, Distance to solution: 1.7298479086023508\n",
      "Iteration 5: x = [-0.43652341  0.17390652], ||grad|| = 19.267478008840097, Distance to solution: 1.6571149480415304\n",
      "Iteration 6: x = [-0.24058742  0.01267462], ||grad|| = 6.669921132307837, Distance to solution: 1.5855183853655974\n",
      "Iteration 7: x = [-0.11704185 -0.00156471], ||grad|| = 11.332343047335005, Distance to solution: 1.5003047592240202\n",
      "Iteration 8: x = [ 0.0637983  -0.03388206], ||grad|| = 4.244248948524616, Distance to solution: 1.3947708514373585\n",
      "Iteration 9: x = [0.17277991 0.01797591], ||grad|| = 7.644085178593253, Distance to solution: 1.2840032731737314\n",
      "Iteration 10: x = [0.33357253 0.08133187], ||grad|| = 2.51741957219163, Distance to solution: 1.1349346700444298\n",
      "Iteration 11: x = [0.42894331 0.17489678], ||grad|| = 6.55275560485548, Distance to solution: 1.0034445994180548\n",
      "Iteration 12: x = [0.57661377 0.30821197], ||grad|| = 1.8666320389522555, Distance to solution: 0.8110650845582666\n",
      "Iteration 13: x = [0.64893441 0.41588559], ||grad|| = 6.792593703677128, Distance to solution: 0.6814959255453117\n",
      "Iteration 14: x = [0.76150917 0.56542445], ||grad|| = 1.2344735736726293, Distance to solution: 0.4957154312670934\n",
      "Iteration 15: x = [0.82274933 0.6731661 ], ||grad|| = 4.88174124290802, Distance to solution: 0.3718039839014387\n",
      "Iteration 16: x = [0.9139031  0.82653483], ||grad|| = 1.156092387385501, Distance to solution: 0.19365650667081238\n",
      "Iteration 17: x = [0.94536196 0.89271958], ||grad|| = 3.468523117485387, Distance to solution: 0.12039271127101636\n",
      "Iteration 18: x = [0.98641123 0.97122311], ||grad|| = 0.3307267351623792, Distance to solution: 0.031823954015424386\n",
      "Iteration 19: x = [0.99642653 0.99276551], ||grad|| = 0.7650291268412384, Distance to solution: 0.008068921383572793\n",
      "Iteration 20: x = [0.99992972 0.99984718], ||grad|| = 0.03847597584052272, Distance to solution: 0.00016820908693584993\n",
      "Iteration 21: x = [0.99999983 0.99999965], ||grad|| = 0.005362719779474921, Distance to solution: 3.8917202652069283e-07\n",
      "Iteration 22: x = [1. 1.], ||grad|| = 1.8964477642984673e-06, Distance to solution: 4.0486691962495454e-13\n",
      "\n",
      "Summary - Run 2:\n",
      "Number of iterations: 23\n",
      "Final iterate x_k: [1. 1.]\n",
      "The size ||\n",
      "abla f(x_k)||: 0.0\n",
      "The distance to the solution: 0.0\n",
      "\n",
      "Run 3:\n",
      "Iteration 1: x = [1.22151166 0.9691091 ], ||grad|| = 164.3099510072351, Distance to solution: 0.22365523308583468\n",
      "Iteration 2: x = [1.21941394 1.48696595], ||grad|| = 276.5198530522295, Distance to solution: 0.5341145157964874\n",
      "Iteration 3: x = [1.12504648 1.25682187], ||grad|| = 0.44097513581815684, Distance to solution: 0.28564680207823073\n",
      "Iteration 4: x = [1.08009071 1.16457492], ||grad|| = 4.616352929025593, Distance to solution: 0.18302848773035651\n",
      "Iteration 5: x = [1.02305434 1.04338705], ||grad|| = 1.1095785284009265, Distance to solution: 0.04913184824030126\n",
      "Iteration 6: x = [1.00908734 1.01806219], ||grad|| = 1.5233053027994239, Distance to solution: 0.020219357593693366\n",
      "Iteration 7: x = [1.00034123 1.00060609], ||grad|| = 0.10447320707846415, Distance to solution: 0.000695545338257463\n",
      "Iteration 8: x = [1.00000514 1.00001017], ||grad|| = 0.03483048215305222, Distance to solution: 1.1396570997463349e-05\n",
      "Iteration 9: x = [1. 1.], ||grad|| = 5.989112363108352e-05, Distance to solution: 2.3638872591673786e-10\n",
      "\n",
      "Summary - Run 3:\n",
      "Number of iterations: 10\n",
      "Final iterate x_k: [1. 1.]\n",
      "The size ||\n",
      "abla f(x_k)||: 0.0\n",
      "The distance to the solution: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import line_search\n",
    "\n",
    "# rosenbrock function\n",
    "def rosenbrock(x):\n",
    "    return 100*(x[1] - x[0]**2)**2 + (1 - x[0])**2\n",
    "\n",
    "def rosenbrock_gradient(x):\n",
    "    return np.array([\n",
    "        -400*x[0]*(x[1] - x[0]**2) - 2*(1 - x[0]),\n",
    "        200*(x[1] - x[0]**2)\n",
    "    ])\n",
    "\n",
    "def rosenbrock_hessian(x):\n",
    "    return np.array([\n",
    "        [1200*x[0]**2 - 400*x[1] + 2, -400*x[0]],\n",
    "        [-400*x[0], 200]\n",
    "    ])\n",
    "\n",
    "def backtracking_line_search(func, grad, x, pk, alpha=0.5, beta=0.9):\n",
    "    t = 1.0\n",
    "    while func(x + t * pk) > func(x) + alpha * t * np.dot(grad, pk):\n",
    "        t *= beta\n",
    "    return t\n",
    "\n",
    "# modified newton method with line search and eigenvalue modification\n",
    "def modified_newton_eigen(x0, max_iter=1000, tol=1e-6):\n",
    "    x = np.array(x0)\n",
    "    for k in range(max_iter):\n",
    "        grad = rosenbrock_gradient(x)\n",
    "        hessian = rosenbrock_hessian(x)\n",
    "        \n",
    "        eigvals, eigvecs = np.linalg.eig(hessian)\n",
    "        \n",
    "        min_eigval = np.min(eigvals)\n",
    "        if min_eigval <= 0:\n",
    "            hessian += np.eye(len(x)) * (-min_eigval + 1e-6)\n",
    "        \n",
    "        # Compute search direction\n",
    "        pk = -np.linalg.solve(hessian, grad)\n",
    "        \n",
    "        alpha_k = backtracking_line_search(rosenbrock, grad, x, pk)\n",
    "        if alpha_k is None:\n",
    "            break\n",
    "        \n",
    "        x += alpha_k * pk\n",
    "        \n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            break\n",
    "        \n",
    "        print(f\"Iteration {k+1}: x = {x}, ||grad|| = {np.linalg.norm(grad)}, Distance to solution: {np.linalg.norm(x - np.array([1, 1]))}\")\n",
    "\n",
    "    return x, k+1\n",
    "\n",
    "# Starting points\n",
    "initial_points = [(1.2, 1.2), (-1.2, 1), (0.2, 0.8)]\n",
    "\n",
    "print(\"Task: Implementing modified Newton method with eigenvalue modification\\n\")\n",
    "\n",
    "for i, point in enumerate(initial_points):\n",
    "    print(f\"Run {i+1}:\")\n",
    "    x_opt, iterations = modified_newton_eigen(point)\n",
    "    print(f\"\\nSummary - Run {i+1}:\")\n",
    "    print(f\"Number of iterations: {iterations}\")\n",
    "    print(f\"Final iterate x_k: {x_opt}\")\n",
    "    print(f\"The size ||\\nabla f(x_k)||: {np.linalg.norm(rosenbrock_gradient(x_opt))}\")\n",
    "    print(f\"The distance to the solution: {np.linalg.norm(x_opt - np.array([1, 1]))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "This code implements the modified Newton method with eigenvalue modification for optimizing the Rosenbrock function. The Rosenbrock function is a classic optimization test problem.\n",
    "\n",
    "The method starts from several initial points and iteratively updates the current point towards the minimum of the function. It incorporates a line search algorithm to determine the step size along the search direction.\n",
    "\n",
    "During each iteration, the code prints out the current iterate, the norm of the gradient, and the distance to the solution. The process terminates when either the norm of the gradient falls below a certain threshold or the maximum number of iterations is reached.\n",
    "\n",
    "In the provided output, the method successfully converges to the minimum of the Rosenbrock function from all initial points within a few iterations. The final iterates closely approximate the known minimum at (1, 1).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Newton Hessian</h1>\n",
    "<h3>Other Function</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x_{0},x_{1})=150 \\left( x_{0} \\cdot x_{1} \\right)^{2} + \\left( 0.5 \\cdot x_{0} + 2 \\cdot x_{1} - 2 \\right)^{2}$$\n",
    "$$\\nabla f(x_{0},x_{1})=[\\left(300 \\cdot x_{1}^{2} \\cdot x_{0} + 0.5 \\cdot x_{0} + 2 \\cdot x_{1} - 2\\right), \\left(300 \\cdot x_{0}^{2} \\cdot x_{1} + 4 \\cdot \\left(0.5 \\cdot x_{0} + 2 \\cdot x_{1} - 2\\right)\\right)]^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Implementing modified Newton method with eigenvalue modification\n",
      "\n",
      "For the new function:\n",
      "Run 1:\n",
      "Iteration 1: x = [-0.22877184  0.33638896], ||grad|| = 87.50182855232225\n",
      "Iteration 2: x = [0.051274   1.22087203], ||grad|| = 9.220539125803404\n",
      "Iteration 3: x = [0.04999287 0.90678994], ||grad|| = 23.565828148566457\n",
      "Iteration 4: x = [0.03575594 0.98038837], ||grad|| = 12.170884738814875\n",
      "Iteration 5: x = [0.02733827 0.95251087], ||grad|| = 10.29292776629751\n",
      "Iteration 6: x = [0.01988235 1.00503766], ||grad|| = 7.36055358071187\n",
      "Iteration 7: x = [0.01522492 0.96910115], ||grad|| = 6.0482515317453815\n",
      "Iteration 8: x = [0.01115827 1.0136962 ], ||grad|| = 4.238025131624887\n",
      "Iteration 9: x = [0.00852255 0.97543939], ||grad|| = 3.476923657908385\n",
      "Iteration 10: x = [0.00671156 1.00910301], ||grad|| = 2.3930900527828847\n",
      "Iteration 11: x = [0.00507574 0.98546634], ||grad|| = 2.074261339821473\n",
      "Iteration 12: x = [0.00403152 1.00589694], ||grad|| = 1.4555884165814592\n",
      "Iteration 13: x = [0.00312997 0.99270401], ||grad|| = 1.2390320971487243\n",
      "Iteration 14: x = [0.00242761 1.00391549], ||grad|| = 0.9136378376753437\n",
      "Iteration 15: x = [0.00187802 0.99544312], ||grad|| = 0.744009877204853\n",
      "Iteration 16: x = [0.00146101 1.00257423], ||grad|| = 0.5510180799138104\n",
      "Iteration 17: x = [0.00116078 0.99767396], ||grad|| = 0.4470958031400632\n",
      "Iteration 18: x = [8.75064463e-04 1.00162264e+00], ||grad|| = 0.3429127661531245\n",
      "Iteration 19: x = [6.94222331e-04 9.98571710e-01], ||grad|| = 0.26747355134250156\n",
      "Iteration 20: x = [5.23994753e-04 1.00102014e+00], ||grad|| = 0.2054011319352647\n",
      "Iteration 21: x = [4.15274699e-04 9.99120011e-01], ||grad|| = 0.16009146141323832\n",
      "Iteration 22: x = [3.13726360e-04 1.00064034e+00], ||grad|| = 0.12296517756253202\n",
      "Iteration 23: x = [2.48441712e-04 9.99456707e-01], ||grad|| = 0.09585044594826302\n",
      "Iteration 24: x = [1.87817563e-04 1.00040154e+00], ||grad|| = 0.07358896997776405\n",
      "Iteration 25: x = [1.52560361e-04 9.99737886e-01], ||grad|| = 0.0574004342122477\n",
      "Iteration 26: x = [1.15133106e-04 1.00017559e+00], ||grad|| = 0.04533131995164274\n",
      "Iteration 27: x = [8.56924055e-05 9.99759000e-01], ||grad|| = 0.03499919985749698\n",
      "Iteration 28: x = [7.05950710e-05 1.00007516e+00], ||grad|| = 0.02531703996454953\n",
      "Iteration 29: x = [5.26435467e-05 9.99884870e-01], ||grad|| = 0.021380272942189978\n",
      "Iteration 30: x = [3.98172658e-05 1.00008550e+00], ||grad|| = 0.015606779588220682\n",
      "Iteration 31: x = [3.23314398e-05 9.99944416e-01], ||grad|| = 0.012162146216475274\n",
      "Iteration 32: x = [2.44053969e-05 1.00003740e+00], ||grad|| = 0.00961085526581911\n",
      "Iteration 33: x = [1.81601286e-05 9.99948818e-01], ||grad|| = 0.00741733792542898\n",
      "Iteration 34: x = [1.49631794e-05 1.00001601e+00], ||grad|| = 0.005367175930279744\n",
      "Iteration 35: x = [1.11568348e-05 9.99975545e-01], ||grad|| = 0.004531365266183934\n",
      "Iteration 36: x = [8.43960692e-06 1.00001819e+00], ||grad|| = 0.0033080970238541577\n",
      "Iteration 37: x = [6.85228063e-06 9.99988193e-01], ||grad|| = 0.00257770230785498\n",
      "Iteration 38: x = [5.17278882e-06 1.00000796e+00], ||grad|| = 0.0020370482376373127\n",
      "Iteration 39: x = [3.84879838e-06 9.99989122e-01], ||grad|| = 0.0015721102182258743\n",
      "Iteration 40: x = [3.17142213e-06 1.00000341e+00], ||grad|| = 0.0011375522227105985\n",
      "Iteration 41: x = [2.36457278e-06 9.99994803e-01], ||grad|| = 0.0009604261120760889\n",
      "Iteration 42: x = [1.78877208e-06 1.00000387e+00], ||grad|| = 0.0007011213763910484\n",
      "Iteration 43: x = [1.45228170e-06 9.99997491e-01], ||grad|| = 0.0005463645953543617\n",
      "Iteration 44: x = [1.09636121e-06 1.00000169e+00], ||grad|| = 0.0004317319345216777\n",
      "Iteration 45: x = [8.43778305e-07 9.99998088e-01], ||grad|| = 0.00033321732623219725\n",
      "Iteration 46: x = [6.59028787e-07 1.00000110e+00], ||grad|| = 0.000250101578875\n",
      "Iteration 47: x = [5.06943770e-07 9.99998783e-01], ||grad|| = 0.00020050209162532156\n",
      "Iteration 48: x = [3.96152543e-07 1.00000072e+00], ||grad|| = 0.0001501553455294274\n",
      "Iteration 49: x = [3.13725951e-07 9.99999374e-01], ||grad|| = 0.00012065715441819222\n",
      "Iteration 50: x = [2.37120205e-07 1.00000045e+00], ||grad|| = 9.312528244104663e-05\n",
      "Iteration 51: x = [1.87727902e-07 9.99999613e-01], ||grad|| = 7.22700787746889e-05\n",
      "Iteration 52: x = [1.41931088e-07 1.00000028e+00], ||grad|| = 5.570386211090758e-05\n",
      "Iteration 53: x = [1.12332377e-07 9.99999760e-01], ||grad|| = 4.328934572103189e-05\n",
      "Iteration 54: x = [8.49551054e-08 1.00000018e+00], ||grad|| = 3.331928141371049e-05\n",
      "Iteration 55: x = [6.72169359e-08 9.99999852e-01], ||grad|| = 2.5931126139421492e-05\n",
      "Iteration 56: x = [5.24881256e-08 1.00000008e+00], ||grad|| = 1.992959233649833e-05\n",
      "Iteration 57: x = [4.03843892e-08 9.99999905e-01], ||grad|| = 1.596163661231766e-05\n",
      "Iteration 58: x = [3.15511847e-08 1.00000006e+00], ||grad|| = 1.1965535531661827e-05\n",
      "Iteration 59: x = [2.4262791e-08 9.9999994e-01], ||grad|| = 9.60489461232438e-06\n",
      "Iteration 60: x = [1.94957671e-08 1.00000003e+00], ||grad|| = 7.183617309650122e-06\n",
      "Iteration 61: x = [1.45178708e-08 9.99999963e-01], ||grad|| = 5.916366379170249e-06\n",
      "Iteration 62: x = [1.16689254e-08 1.00000002e+00], ||grad|| = 4.296464524026176e-06\n",
      "Iteration 63: x = [8.68684651e-09 9.99999977e-01], ||grad|| = 3.543006358712073e-06\n",
      "Iteration 64: x = [6.98431246e-09 1.00000001e+00], ||grad|| = 2.569632202247518e-06\n",
      "Iteration 65: x = [5.19778489e-09 9.99999986e-01], ||grad|| = 2.1217855205461894e-06\n",
      "Iteration 66: x = [4.18040934e-09 1.00000001e+00], ||grad|| = 1.5368174400193147e-06\n",
      "Iteration 67: x = [3.21711101e-09 9.99999993e-01], ||grad|| = 1.270703771051233e-06\n",
      "Iteration 68: x = [2.51287097e-09 1.00000000e+00], ||grad|| = 9.534950448021045e-07\n",
      "\n",
      "Summary - Run 1:\n",
      "Number of iterations: 68\n",
      "Final iterate x_k: [2.51287097e-09 1.00000000e+00]\n",
      "The size ||\n",
      "abla f(x_k)||: 7.646118680619188e-07\n",
      "The distance to the solution: 0.999999997487129\n",
      "\n",
      "Run 2:\n",
      "\n",
      "Summary - Run 2:\n",
      "Number of iterations: 1\n",
      "Final iterate x_k: [3.8 0.1]\n",
      "The size ||\n",
      "abla f(x_k)||: 433.75247549725873\n",
      "The distance to the solution: 2.9410882339705484\n",
      "\n",
      "Run 3:\n",
      "\n",
      "Summary - Run 3:\n",
      "Number of iterations: 1\n",
      "Final iterate x_k: [1.9 0.6]\n",
      "The size ||\n",
      "abla f(x_k)||: 682.0474928478221\n",
      "The distance to the solution: 0.9848857801796104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func_new(x):\n",
    "    return 150 * (x[0] * x[1])**2 + (0.5 * x[0] + 2 * x[1] - 2)**2\n",
    "\n",
    "def gradient_new(x):\n",
    "    return np.array([\n",
    "        (300 * x[1]**2 * x[0] + 0.5 * x[0] + 2 * x[1] - 2),\n",
    "        (300 * x[0]**2 * x[1] + 4 * (0.5 * x[0] + 2 * x[1] - 2))\n",
    "    ])\n",
    "\n",
    "def hessian_new(x):\n",
    "    return np.array([\n",
    "        [1200 * x[1]**2 + 1800 * x[0]**2 * x[1]**2 + 0.25, 600 * x[0] * x[1] + 600 * x[0]**3 * x[1] - 1],\n",
    "        [600 * x[0] * x[1] + 600 * x[0]**3 * x[1] - 1, 300 * x[0]**2 * x[1]**2 + 4]\n",
    "    ])\n",
    "\n",
    "def backtracking_line_search(func, grad, x, pk, alpha=0.5, beta=0.9):\n",
    "    t = 1.0\n",
    "    while func(x + t * pk) > func(x) + alpha * t * np.dot(grad, pk):\n",
    "        t *= beta\n",
    "        if t < 1e-8:\n",
    "            return None  \n",
    "    return t\n",
    "\n",
    "# implementing modified NM with eigenvalue modification for both functions\n",
    "def modified_newton_eigen_both(func, gradient, hessian, x0, max_iter=1000, tol=1e-6):\n",
    "    x = np.array(x0)\n",
    "    for k in range(max_iter):\n",
    "        grad = gradient(x)\n",
    "        hess = hessian(x)\n",
    "        \n",
    "        eigvals, eigvecs = np.linalg.eig(hess)\n",
    "        \n",
    "        min_eigval = np.min(eigvals)\n",
    "        if min_eigval <= 0:\n",
    "            hess += np.eye(len(x)) * (-min_eigval + 1e-6)\n",
    "        \n",
    "        pk = -np.linalg.solve(hess, grad)\n",
    "        \n",
    "        alpha_k = backtracking_line_search(func, grad, x, pk)\n",
    "        if alpha_k is None:\n",
    "            break  # Line search failed\n",
    "        \n",
    "        x += alpha_k * pk\n",
    "        \n",
    "        print(f\"Iteration {k+1}: x = {x}, ||grad|| = {np.linalg.norm(grad)}\")\n",
    "        \n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            break\n",
    "        \n",
    "    return x, k+1\n",
    "\n",
    "initial_points = [(-0.2, 1.2), (3.8, 0.1), (1.9, 0.6)]\n",
    "\n",
    "print(\"Task: Implementing modified Newton method with eigenvalue modification\\n\")\n",
    "\n",
    "print(\"For the new function:\")\n",
    "for i, point in enumerate(initial_points):\n",
    "    print(f\"Run {i+1}:\")\n",
    "    x_opt, iterations = modified_newton_eigen_both(func_new, gradient_new, hessian_new, point)\n",
    "    print(f\"\\nSummary - Run {i+1}:\")\n",
    "    print(f\"Number of iterations: {iterations}\")\n",
    "    print(f\"Final iterate x_k: {x_opt}\")\n",
    "    print(f\"The size ||\\nabla f(x_k)||: {np.linalg.norm(gradient_new(x_opt))}\")\n",
    "    print(f\"The distance to the solution: {np.linalg.norm(x_opt - np.array([1, 1]))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task 2: Linear Search</h1>\n",
    "<h3>Rosenbrock Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on Linear Conjugate Gradient Method for Rosenbrock Function Minimization\n",
      "\n",
      "Implemented Task: Implementing linear conjugate gradient method\n",
      "\n",
      "Run 1:\n",
      "Iteration 1: x = [-0.57738004  0.23150256], ||grad|| = 33.56964565437427, Distance to solution: 1.7546270509408355\n",
      "Iteration 2: x = [-0.52183357  0.26734493], ||grad|| = 4.1992144342674615, Distance to solution: 1.6890118017020699\n",
      "Iteration 3: x = [-0.50958544  0.27075727], ||grad|| = 2.342920331087344, Distance to solution: 1.6764972866622871\n",
      "Iteration 4: x = [-0.15056058 -0.03412705], ||grad|| = 12.718723488009237, Distance to solution: 1.5469998116288366\n",
      "Iteration 5: x = [-0.15056058 -0.03412705], ||grad|| = 12.71872348800926, Distance to solution: 1.5469998116288364\n",
      "Iteration 6: x = [-0.11977559 -0.04693541], ||grad|| = 13.304280760702651, Distance to solution: 1.5329615550390834\n",
      "Iteration 7: x = [-0.04490049 -0.06570266], ||grad|| = 13.941409937081726, Distance to solution: 1.4924942894776339\n",
      "Iteration 8: x = [ 0.01090722 -0.07158583], ||grad|| = 14.437330646461545, Distance to solution: 1.4582869122939948\n",
      "Iteration 9: x = [ 0.07169504 -0.06980783], ||grad|| = 14.992460072709319, Distance to solution: 1.4164176282003553\n",
      "Iteration 10: x = [ 0.13054361 -0.06047455], ||grad|| = 15.674208494055057, Distance to solution: 1.3713353660201795\n",
      "Iteration 11: x = [ 0.1936941  -0.04240481], ||grad|| = 16.627533734965542, Distance to solution: 1.317853173404425\n",
      "Iteration 12: x = [ 0.24937481 -0.01936258], ||grad|| = 17.60739764507765, Distance to solution: 1.2659139909652217\n",
      "Iteration 13: x = [0.30908447 0.01318048], ||grad|| = 18.67389663222073, Distance to solution: 1.2046480922125327\n",
      "Iteration 14: x = [0.37262898 0.05655629], ||grad|| = 19.803066665355647, Distance to solution: 1.132996214126557\n",
      "Iteration 15: x = [0.44700098 0.11827456], ||grad|| = 21.152538676671206, Distance to solution: 1.04079184529564\n",
      "Iteration 16: x = [0.51783055 0.18835313], ||grad|| = 22.291822188848787, Distance to solution: 0.9440646281327295\n",
      "Iteration 17: x = [0.60704855 0.29254019], ||grad|| = 23.296754289327424, Distance to solution: 0.809265232060803\n",
      "Iteration 18: x = [0.69552867 0.41404382], ||grad|| = 23.395798076406138, Distance to solution: 0.6603388772622037\n",
      "Iteration 19: x = [0.80485532 0.59184294], ||grad|| = 20.87464478946844, Distance to solution: 0.4524087023587689\n",
      "Iteration 20: x = [0.91880965 0.81945235], ||grad|| = 10.2172089490162, Distance to solution: 0.19796294598877867\n",
      "Iteration 21: x = [0.93484439 0.87325617], ||grad|| = 0.18316475010576025, Distance to solution: 0.14251053518173842\n",
      "Iteration 22: x = [0.93470553 0.87343736], ||grad|| = 0.06330891286830521, Distance to solution: 0.14241302470646106\n",
      "Iteration 23: x = [0.93775617 0.88063438], ||grad|| = 0.6429262318192117, Distance to solution: 0.13461963499566157\n",
      "Iteration 24: x = [0.99470964 0.98794247], ||grad|| = 0.66068372352063, Distance to solution: 0.013167079484088857\n",
      "Iteration 25: x = [0.99873654 0.99737567], ||grad|| = 0.041984803994271645, Distance to solution: 0.002912631153083996\n",
      "Iteration 26: x = [0.99871304 0.99742235], ||grad|| = 0.0011566089718718956, Distance to solution: 0.002881064946562132\n",
      "Iteration 27: x = [0.99874231 0.9975022 ], ||grad|| = 0.009462230348976542, Distance to solution: 0.0027965675254264656\n",
      "Iteration 28: x = [0.99986094 0.99970374], ||grad|| = 0.007868881604724768, Distance to solution: 0.00032726955393941727\n",
      "Iteration 29: x = [0.99988009 0.99975988], ||grad|| = 0.00012737521528540974, Distance to solution: 0.0002683973891710772\n",
      "Iteration 30: x = [0.99988052 0.99976017], ||grad|| = 0.0002117034533579968, Distance to solution: 0.00026794014530365527\n",
      "Iteration 31: x = [0.99998664 0.99997048], ||grad|| = 0.001229375146212662, Distance to solution: 3.2401813979161624e-05\n",
      "Iteration 32: x = [0.99999263 0.99998524], ||grad|| = 9.16294537746799e-06, Distance to solution: 1.6504025203123286e-05\n",
      "Iteration 33: x = [0.99999265 0.99998524], ||grad|| = 1.0082290392230967e-05, Distance to solution: 1.648755939963444e-05\n",
      "\n",
      "Summary - Run 1:\n",
      "Number of iterations: 34\n",
      "Final iterate x_k: [0.99999959 0.99999918]\n",
      "The size ||∇f(x_k)||: 9.593576740674355e-07\n",
      "The distance to the solution: 9.167282641691157e-07\n",
      "\n",
      "Run 2:\n",
      "Iteration 1: x = [2.13915099 0.31847663], ||grad|| = 3743.3746547326155, Distance to solution: 1.3274558633869182\n",
      "Iteration 2: x = [1.29817074 0.5022456 ], ||grad|| = 658.8409553371398, Distance to solution: 0.5802286053120695\n",
      "Iteration 3: x = [0.91885399 0.63702054], ||grad|| = 86.58713298905037, Distance to solution: 0.37193919049286267\n",
      "Iteration 4: x = [0.83392763 0.68098998], ||grad|| = 5.3361440412236245, Distance to solution: 0.3596490299879782\n",
      "Iteration 5: x = [0.82823989 0.6846024 ], ||grad|| = 0.29815002041252375, Distance to solution: 0.3591339320248885\n",
      "Iteration 6: x = [0.82800921 0.68511517], ||grad|| = 0.20760916262572682, Distance to solution: 0.35879421090428015\n",
      "Iteration 7: x = [0.85050708 0.72869289], ||grad|| = 2.3662493228639057, Distance to solution: 0.3097671427052736\n",
      "Iteration 8: x = [0.93346277 0.8654512 ], ||grad|| = 2.3832747424986076, Distance to solution: 0.1501019107436826\n",
      "Iteration 9: x = [0.97748383 0.95060465], ||grad|| = 2.098792077376758, Distance to solution: 0.0542851640707156\n",
      "Iteration 10: x = [0.98873726 0.97722258], ||grad|| = 0.14812271995426005, Distance to solution: 0.025409840939508984\n",
      "Iteration 11: x = [0.98866615 0.97741425], ||grad|| = 0.010237051086486324, Distance to solution: 0.025269982982395363\n",
      "Iteration 12: x = [0.98897891 0.97823263], ||grad|| = 0.08820223486625049, Distance to solution: 0.02439842085616025\n",
      "Iteration 13: x = [0.99937462 0.99856257], ||grad|| = 0.08250144637255664, Distance to solution: 0.0015675765280177255\n",
      "Iteration 14: x = [0.99964361 0.99928088], ||grad|| = 0.002273364669410434, Distance to solution: 0.0008025916526011373\n",
      "Iteration 15: x = [0.999642  0.9992826], ||grad|| = 0.0003233675498712004, Distance to solution: 0.0008017608284866073\n",
      "Iteration 16: x = [0.99964293 0.99928716], ||grad|| = 0.0012092273847817512, Distance to solution: 0.0007972670956303618\n",
      "Iteration 17: x = [0.99978239 0.99958173], ||grad|| = 0.007944923595670748, Distance to solution: 0.0004714939614210242\n",
      "Iteration 18: x = [1.00000507 1.00001085], ||grad|| = 0.0003084672366587697, Distance to solution: 1.1971196286034509e-05\n",
      "Iteration 19: x = [1.00000547 1.00001099], ||grad|| = 9.756075406911348e-06, Distance to solution: 1.2276349247338295e-05\n",
      "Iteration 20: x = [1.00000548 1.00001098], ||grad|| = 5.254662899760227e-06, Distance to solution: 1.2270947925497434e-05\n",
      "Iteration 21: x = [1.00000534 1.0000106 ], ||grad|| = 4.3664084181955705e-05, Distance to solution: 1.186857828183075e-05\n",
      "Iteration 22: x = [1.0000005  1.00000085], ||grad|| = 6.557545499206157e-05, Distance to solution: 9.860882296240663e-07\n",
      "Iteration 23: x = [1.00000003 1.00000004], ||grad|| = 4.758856766991472e-06, Distance to solution: 4.715668770324156e-08\n",
      "\n",
      "Summary - Run 2:\n",
      "Number of iterations: 24\n",
      "Final iterate x_k: [1.00000002 1.00000004]\n",
      "The size ||∇f(x_k)||: 3.7417435506436237e-07\n",
      "The distance to the solution: 4.2461036390039194e-08\n",
      "\n",
      "Run 3:\n",
      "Iteration 1: x = [1.21388817 0.78041379], ||grad|| = 364.37038730186686, Distance to solution: 0.306539159903544\n",
      "Iteration 2: x = [0.99327531 0.86662877], ||grad|| = 53.35045817629471, Distance to solution: 0.13354065520065284\n",
      "Iteration 3: x = [0.94511073 0.89006832], ||grad|| = 1.2580660178257144, Distance to solution: 0.12287312871999351\n",
      "Iteration 4: x = [0.94392413 0.89075631], ||grad|| = 0.05253217665699375, Distance to solution: 0.12279531010687103\n",
      "Iteration 5: x = [0.94741387 0.89883151], ||grad|| = 0.6256256134026623, Distance to solution: 0.11401914247473181\n",
      "Iteration 6: x = [0.98982539 0.97808919], ||grad|| = 0.720503230259886, Distance to solution: 0.024157939793748636\n",
      "Iteration 7: x = [0.99639067 0.99282791], ||grad|| = 0.02164948757064305, Distance to solution: 0.00802907739491673\n",
      "Iteration 8: x = [0.99641641 0.99282953], ||grad|| = 0.0033092764353291446, Distance to solution: 0.008016099624828443\n",
      "Iteration 9: x = [0.99657511 0.99322602], ||grad|| = 0.034832014895024625, Distance to solution: 0.007590562559092651\n",
      "Iteration 10: x = [0.99980521 0.99958539], ||grad|| = 0.010864579151140774, Distance to solution: 0.0004580890554843653\n",
      "Iteration 11: x = [0.99981326 0.99962669], ||grad|| = 0.00042796219786227815, Distance to solution: 0.00041741486035384796\n",
      "Iteration 12: x = [0.99981378 0.99962673], ||grad|| = 0.00017448284326529331, Distance to solution: 0.00041714820803899055\n",
      "Iteration 13: x = [0.99983689 0.9996674 ], ||grad|| = 0.00258223177432137, Distance to solution: 0.0003704427295581684\n",
      "Iteration 14: x = [0.99999315 0.99998335], ||grad|| = 0.0013116518123110208, Distance to solution: 1.800391560501983e-05\n",
      "Iteration 15: x = [0.99999694 0.99999382], ||grad|| = 1.785321197473948e-05, Distance to solution: 6.8926244479306395e-06\n",
      "Iteration 16: x = [0.99999693 0.99999384], ||grad|| = 2.800819821248394e-06, Distance to solution: 6.8879234551585635e-06\n",
      "Iteration 17: x = [0.99999693 0.99999386], ||grad|| = 8.390058769746898e-06, Distance to solution: 6.862866989645528e-06\n",
      "Iteration 18: x = [0.99999789 0.99999592], ||grad|| = 6.796227442817112e-05, Distance to solution: 4.589488410644767e-06\n",
      "Iteration 19: x = [0.99999999 1.00000003], ||grad|| = 2.1878014086997583e-05, Distance to solution: 3.420278978790018e-08\n",
      "Iteration 20: x = [1.00000008 1.00000017], ||grad|| = 1.381465165548684e-06, Distance to solution: 1.930805784056711e-07\n",
      "\n",
      "Summary - Run 3:\n",
      "Number of iterations: 21\n",
      "Final iterate x_k: [1.00000009 1.00000017]\n",
      "The size ||∇f(x_k)||: 1.3459971038514803e-07\n",
      "The distance to the solution: 1.9367430934694398e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import line_search\n",
    "\n",
    "def rosenbrock(x):\n",
    "    return 100*(x[1] - x[0]**2)**2 + (1 - x[0])**2\n",
    "\n",
    "def rosenbrock_gradient(x):\n",
    "    return np.array([\n",
    "        -400*x[0]*(x[1] - x[0]**2) - 2*(1 - x[0]),\n",
    "        200*(x[1] - x[0]**2)\n",
    "    ])\n",
    "\n",
    "def rosenbrock_hessian(x):\n",
    "    return np.array([\n",
    "        [1200*x[0]**2 - 400*x[1] + 2, -400*x[0]],\n",
    "        [-400*x[0], 200]\n",
    "    ])\n",
    "\n",
    "# linear Conjugate Gradient Method\n",
    "def linear_conjugate_gradient(x0, max_iter=1000, tol=1e-6):\n",
    "    x = np.array(x0)\n",
    "    grad = rosenbrock_gradient(x)\n",
    "    d = -grad\n",
    "    k = 0\n",
    "    while k < max_iter:\n",
    "        # Line search\n",
    "        alpha_k = backtracking_line_search(rosenbrock, grad, x, d)\n",
    "        if alpha_k is None:\n",
    "            break\n",
    "        x += alpha_k * d\n",
    "        grad_new = rosenbrock_gradient(x)\n",
    "        beta_k = np.dot(grad_new, grad_new) / np.dot(grad, grad)\n",
    "        d = -grad_new + beta_k * d\n",
    "        grad = grad_new\n",
    "        k += 1\n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            break\n",
    "        print(f\"Iteration {k}: x = {x}, ||grad|| = {np.linalg.norm(grad)}, Distance to solution: {np.linalg.norm(x - np.array([1, 1]))}\")\n",
    "    return x, k\n",
    "\n",
    "def backtracking_line_search(func, grad, x, pk, alpha=0.5, beta=0.9):\n",
    "    t = 1.0\n",
    "    while func(x + t * pk) > func(x) + alpha * t * np.dot(grad, pk):\n",
    "        t *= beta\n",
    "    return t\n",
    "\n",
    "initial_points = [(-0.2, 1.2), (3.8, 0.1), (1.9, 0.6)]\n",
    "\n",
    "print(\"Report on Linear Conjugate Gradient Method for Rosenbrock Function Minimization\\n\")\n",
    "print(\"Implemented Task: Implementing linear conjugate gradient method\\n\")\n",
    "\n",
    "for i, point in enumerate(initial_points):\n",
    "    print(f\"Run {i+1}:\")\n",
    "    x_opt, iterations = linear_conjugate_gradient(point)\n",
    "    print(f\"\\nSummary - Run {i+1}:\")\n",
    "    print(f\"Number of iterations: {iterations}\")\n",
    "    print(f\"Final iterate x_k: {x_opt}\")\n",
    "    print(f\"The size ||∇f(x_k)||: {np.linalg.norm(rosenbrock_gradient(x_opt))}\")\n",
    "    print(f\"The distance to the solution: {np.linalg.norm(x_opt - np.array([1, 1]))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This code implements the Linear Conjugate Gradient Method for minimizing the Rosenbrock function. The method starts from several initial points and iteratively updates the current point towards the minimum of the function using conjugate gradients.\n",
    "\n",
    "During each iteration, the code prints out the current iterate, the norm of the gradient, and the distance to the solution. The process terminates when either the norm of the gradient falls below a certain threshold or the maximum number of iterations is reached.\n",
    "\n",
    "In the provided output, the method successfully converges to the minimum of the Rosenbrock function from all initial points within a few iterations. The final iterates closely approximate the known minimum at (1, 1).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Other Function (see above)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on Linear Conjugate Gradient Method for Function Minimization (f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 - 2)^2)\n",
      "\n",
      "Implemented Task: Implementing linear conjugate gradient method\n",
      "\n",
      "Run 1:\n",
      "Iteration 1: x = [-0.00898446  1.16539091], ||grad|| = 3.5910675296304335, Distance to solution: 0.1656347625109544\n",
      "Iteration 2: x = [-4.07712018e-04  1.16203932e+00], ||grad|| = 1.3052421611286698, Distance to solution: 0.1620398304939217\n",
      "Iteration 3: x = [0.00992587 1.11138628], ||grad|| = 4.018215915386389, Distance to solution: 0.11182765885937865\n",
      "Iteration 4: x = [0.00247702 1.00587519], ||grad|| = 0.7667426708834107, Distance to solution: 0.006376006835677172\n",
      "Iteration 5: x = [3.26297121e-05 1.00405769e+00], ||grad|| = 0.03717549209632444, Distance to solution: 0.004057816800104432\n",
      "Iteration 6: x = [-1.81673000e-04  1.00369207e+00], ||grad|| = 0.05584387896803787, Distance to solution: 0.0036965370139106996\n",
      "Iteration 7: x = [-8.78174106e-05  1.00006099e+00], ||grad|| = 0.026272254617372946, Distance to solution: 0.00010691736859134863\n",
      "Iteration 8: x = [-6.02891484e-06  9.99988801e-01], ||grad|| = 0.0018368613472439603, Distance to solution: 1.2718992706776119e-05\n",
      "Iteration 9: x = [-4.76392494e-08  9.99988757e-01], ||grad|| = 9.726874911551722e-05, Distance to solution: 1.1242977681507174e-05\n",
      "Iteration 10: x = [5.77773482e-07 9.99990087e-01], ||grad|| = 0.00017250724735553064, Distance to solution: 9.92944835485451e-06\n",
      "Iteration 11: x = [5.94792592e-08 9.99999129e-01], ||grad|| = 1.752487802719866e-05, Distance to solution: 8.727437430389918e-07\n",
      "Iteration 12: x = [-8.75700841e-09  9.99999173e-01], ||grad|| = 7.894036509793248e-06, Distance to solution: 8.266163142494997e-07\n",
      "Iteration 13: x = [5.37873675e-08 9.99999740e-01], ||grad|| = 1.5767384807406127e-05, Distance to solution: 2.650786348887484e-07\n",
      "Iteration 14: x = [-8.62418575e-10  9.99999912e-01], ||grad|| = 8.29392647890654e-07, Distance to solution: 8.804129680410907e-08\n",
      "\n",
      "Summary - Run 1:\n",
      "Number of iterations: 14\n",
      "Final iterate x_k: [-8.62418575e-10  9.99999912e-01]\n",
      "The size ||∇f(x_k)||: 8.29392647890654e-07\n",
      "The distance to the solution: 8.804129680410907e-08\n",
      "\n",
      "Run 2:\n",
      "Iteration 1: x = [3.79748754 0.00526946], ||grad|| = 22.43431882302345, Distance to solution: 3.925608296190992\n",
      "Iteration 2: x = [3.79749373e+00 1.14732230e-04], ||grad|| = 0.13680823896844657, Distance to solution: 3.9269236281424558\n",
      "Iteration 3: x = [3.79753987e+00 7.21847633e-05], ||grad|| = 0.13670793364306805, Distance to solution: 3.926979079910411\n",
      "Iteration 4: x = [ 3.96111242e+00 -7.11624568e-04], ||grad|| = 3.433232678942959, Distance to solution: 4.085564266993491\n",
      "Iteration 5: x = [ 3.99203472e+00 -2.63741133e-05], ||grad|| = 0.14229081769844026, Distance to solution: 4.115385033962565\n",
      "Iteration 6: x = [3.99207854e+00 2.54627571e-06], ||grad|| = 0.005381511040468645, Distance to solution: 4.115420509899819\n",
      "Iteration 7: x = [3.99208030e+00 4.13277535e-06], ||grad|| = 0.005589020055934008, Distance to solution: 4.115421828926331\n",
      "Iteration 8: x = [3.99312123e+00 2.96669727e-05], ||grad|| = 0.12843636568272018, Distance to solution: 4.11642536827246\n",
      "Iteration 9: x = [3.99970746e+00 4.22291312e-06], ||grad|| = 0.0197161968422131, Distance to solution: 4.122820793452053\n",
      "Iteration 10: x = [3.99972845e+00 2.65274035e-07], ||grad|| = 0.0007445508818489156, Distance to solution: 4.122842119555692\n",
      "Iteration 11: x = [3.99972851e+00 1.15666782e-07], ||grad|| = 0.0001361436046356532, Distance to solution: 4.122842210685403\n",
      "Iteration 12: x = [3.99972890e+00 1.02088615e-08], ||grad|| = 0.0005113996735881985, Distance to solution: 4.12284262188989\n",
      "Iteration 13: x = [ 3.99976874e+00 -9.05242625e-07], ||grad|| = 0.0048158472094591, Distance to solution: 4.122881494788789\n",
      "Iteration 14: x = [ 3.99999716e+00 -4.74194990e-07], ||grad|| = 0.00228561512459905, Distance to solution: 4.123102981724723\n",
      "Iteration 15: x = [ 4.00000488e+00 -5.51497462e-08], ||grad|| = 0.00025541351457421295, Distance to solution: 4.123110372188279\n",
      "Iteration 16: x = [ 4.00000497e+00 -4.71963984e-09], ||grad|| = 1.2981015685057184e-05, Distance to solution: 4.123110453116197\n",
      "Iteration 17: x = [ 4.00000497e+00 -2.06942250e-09], ||grad|| = 2.4832011296810653e-06, Distance to solution: 4.123110452268099\n",
      "Iteration 18: x = [4.00000496e+00 4.74856764e-10], ||grad|| = 1.2456215674116726e-05, Distance to solution: 4.123110439038333\n",
      "Iteration 19: x = [4.00000070e+00 1.43931317e-08], ||grad|| = 7.060367598654348e-05, Distance to solution: 4.123106301448725\n",
      "Iteration 20: x = [4.00000024e+00 4.80291052e-10], ||grad|| = 2.7861958576712095e-06, Distance to solution: 4.123105855614053\n",
      "Iteration 21: x = [ 4.00000024e+00 -8.65454649e-11], ||grad|| = 1.310965944186075e-07, Distance to solution: 4.123105855099133\n",
      "\n",
      "Summary - Run 2:\n",
      "Number of iterations: 21\n",
      "Final iterate x_k: [ 4.00000024e+00 -8.65454649e-11]\n",
      "The size ||∇f(x_k)||: 1.310965944186075e-07\n",
      "The distance to the solution: 4.123105855099133\n",
      "\n",
      "Run 3:\n",
      "Iteration 1: x = [1.74115068 0.09688047], ||grad|| = 84.46157403829949, Distance to solution: 1.961435848215597\n",
      "Iteration 2: x = [1.73435481 0.00678304], ||grad|| = 1.975433845646016, Distance to solution: 1.998616156846909\n",
      "Iteration 3: x = [1.73594347 0.004315  ], ||grad|| = 1.2615553467353262, Distance to solution: 2.0012217097046814\n",
      "Iteration 4: x = [ 1.9699149  -0.01053015], ||grad|| = 16.43197584128303, Distance to solution: 2.213986425092567\n",
      "Iteration 5: x = [ 3.48989716 -0.01268614], ||grad|| = 47.47464480110158, Distance to solution: 3.633856822859999\n",
      "Iteration 6: x = [4.15393770e+00 5.99673979e-04], ||grad|| = 3.417825120430286, Distance to solution: 4.272469944812359\n",
      "Iteration 7: x = [4.15595607e+00 3.56617263e-05], ||grad|| = 0.5030735291194761, Distance to solution: 4.2745642479634\n",
      "Iteration 8: x = [ 4.15598299e+00 -5.44890539e-05], ||grad|| = 0.08317517421865517, Distance to solution: 4.274611515480227\n",
      "Iteration 9: x = [ 4.15593709e+00 -8.24714931e-05], ||grad|| = 0.13977651596000457, Distance to solution: 4.274573429814749\n",
      "Iteration 10: x = [ 4.14616068e+00 -4.26071579e-04], ||grad|| = 1.9097961001563815, Distance to solution: 4.265149554115007\n",
      "Iteration 11: x = [ 4.00038115e+00 -3.15616102e-04], ||grad|| = 1.517008682191628, Distance to solution: 4.123551948338246\n",
      "Iteration 12: x = [ 3.99377791e+00 -1.23279174e-05], ||grad|| = 0.07160155102093561, Distance to solution: 4.1170725791465\n",
      "Iteration 13: x = [3.99376522e+00 9.38937485e-07], ||grad|| = 0.008556534925630264, Distance to solution: 4.117057052053512\n",
      "Iteration 14: x = [3.99376563e+00 2.71640635e-06], ||grad|| = 0.003160172014623475, Distance to solution: 4.1170570193255465\n",
      "Iteration 15: x = [3.99377981e+00 5.56314024e-06], ||grad|| = 0.014557880351828603, Distance to solution: 4.117070084520953\n",
      "Iteration 16: x = [3.99917768e+00 2.33095560e-05], ||grad|| = 0.11038231360089314, Distance to solution: 4.122302211679359\n",
      "Iteration 17: x = [4.00012218e+00 2.29889299e-06], ||grad|| = 0.011298298971037023, Distance to solution: 4.12322359843941\n",
      "Iteration 18: x = [4.00013018e+00 1.21230467e-07], ||grad|| = 0.0008458044932438785, Distance to solution: 4.123231891160005\n",
      "Iteration 19: x = [ 4.00013022e+00 -4.02036306e-08], ||grad|| = 9.345268966610833e-05, Distance to solution: 4.123231962610092\n",
      "Iteration 20: x = [ 4.00013020e+00 -6.36559315e-08], ||grad|| = 7.942506169797306e-05, Distance to solution: 4.123231950059482\n",
      "Iteration 21: x = [ 4.00012901e+00 -1.80462325e-07], ||grad|| = 0.0006130677091797387, Distance to solution: 4.123230825543904\n",
      "Iteration 22: x = [ 4.00004075e+00 -6.61493387e-07], ||grad|| = 0.0030990901894970254, Distance to solution: 4.123145316100774\n",
      "Iteration 23: x = [ 3.99999501e+00 -7.48459915e-08], ||grad|| = 0.0003698436939430871, Distance to solution: 4.1231008048868665\n",
      "Iteration 24: x = [ 3.99999459e+00 -3.91681723e-09], ||grad|| = 2.9785393871158067e-05, Distance to solution: 4.123100373549705\n",
      "Iteration 25: x = [3.99999458e+00 1.79222912e-09], ||grad|| = 3.4973287579193314e-06, Distance to solution: 4.123100369945165\n",
      "Iteration 26: x = [3.99999458e+00 2.77703308e-09], ||grad|| = 3.6949975824472987e-06, Distance to solution: 4.123100370613229\n",
      "Iteration 27: x = [3.99999466e+00 8.77978780e-09], ||grad|| = 3.163944865052571e-05, Distance to solution: 4.123100440432189\n",
      "Iteration 28: x = [3.99999861e+00 2.38840076e-08], ||grad|| = 0.0001120563675386645, Distance to solution: 4.123104271457885\n",
      "Iteration 29: x = [3.99999985e+00 1.42527523e-09], ||grad|| = 6.555844966997115e-06, Distance to solution: 4.12310548107612\n",
      "Iteration 30: x = [3.99999985e+00 7.40288567e-11], ||grad|| = 9.771217236819079e-08, Distance to solution: 4.123105484756025\n",
      "\n",
      "Summary - Run 3:\n",
      "Number of iterations: 30\n",
      "Final iterate x_k: [3.99999985e+00 7.40288567e-11]\n",
      "The size ||∇f(x_k)||: 9.771217236819079e-08\n",
      "The distance to the solution: 4.123105484756025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define the function and its gradient\n",
    "def func(x):\n",
    "    return 150 * (x[0] * x[1])**2 + (0.5 * x[0] + 2 * x[1] - 2)**2\n",
    "\n",
    "def gradient(x):\n",
    "    return np.array([\n",
    "        (300 * x[1]**2 * x[0] + 0.5 * x[0] + 2 * x[1] - 2),\n",
    "        (300 * x[0]**2 * x[1] + 4 * (0.5 * x[0] + 2 * x[1] - 2))\n",
    "    ])\n",
    "\n",
    "# Linear Conjugate Gradient Method\n",
    "def linear_conjugate_gradient(func, grad, x0, max_iter=1000, tol=1e-6):\n",
    "    x = np.array(x0)\n",
    "    g = grad(x)\n",
    "    d = -g\n",
    "    k = 0\n",
    "    while k < max_iter:\n",
    "        # Line search\n",
    "        alpha_k = backtracking_line_search(func, grad, x, d)\n",
    "        if alpha_k is None:\n",
    "            break\n",
    "        x += alpha_k * d\n",
    "        g_new = grad(x)\n",
    "        beta_k = np.dot(g_new, g_new) / np.dot(g, g)\n",
    "        d = -g_new + beta_k * d\n",
    "        g = g_new\n",
    "        k += 1\n",
    "        print(f\"Iteration {k}: x = {x}, ||grad|| = {np.linalg.norm(g)}, Distance to solution: {np.linalg.norm(x - np.array([0, 1]))}\")\n",
    "        if np.linalg.norm(g) < tol:\n",
    "            break\n",
    "    return x, k\n",
    "\n",
    "def backtracking_line_search(func, grad, x, pk, alpha=0.5, beta=0.9):\n",
    "    t = 1.0\n",
    "    while func(x + t * pk) > func(x) + alpha * t * np.dot(grad(x), pk):\n",
    "        t *= beta\n",
    "    return t\n",
    "\n",
    "initial_points = [(-0.2, 1.2), (3.8, 0.1), (1.9, 0.6)]\n",
    "\n",
    "print(\"Report on Linear Conjugate Gradient Method for Function Minimization (f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 - 2)^2)\\n\")\n",
    "print(\"Implemented Task: Implementing linear conjugate gradient method\\n\")\n",
    "\n",
    "for i, point in enumerate(initial_points):\n",
    "    print(f\"Run {i+1}:\")\n",
    "    x_opt, iterations = linear_conjugate_gradient(func, gradient, point)\n",
    "    print(f\"\\nSummary - Run {i+1}:\")\n",
    "    print(f\"Number of iterations: {iterations}\")\n",
    "    print(f\"Final iterate x_k: {x_opt}\")\n",
    "    print(f\"The size ||∇f(x_k)||: {np.linalg.norm(gradient(x_opt))}\")\n",
    "    print(f\"The distance to the solution: {np.linalg.norm(x_opt - np.array([0, 1]))}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
