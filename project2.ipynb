{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Newton Hessian</h1>\n",
    "<h3>Rosenbrock Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Implementing modified Newton method with eigenvalue modification\n",
      "\n",
      "Run 1:\n",
      "Iteration 1: x = [1.19591837 1.43020408], ||grad|| = 125.16932531574977, Distance to solution: 0.47271509233076564\n",
      "Iteration 2: x = [1.10252241 1.20682417], ||grad|| = 0.3998200870053441, Distance to solution: 0.2308399464578291\n",
      "Iteration 3: x = [1.0651913  1.13323889], ||grad|| = 4.4156957287332945, Distance to solution: 0.14833241618491672\n",
      "Iteration 4: x = [1.01420971 1.02602221], ||grad|| = 0.7759545183917276, Distance to solution: 0.02964914027637089\n",
      "Iteration 5: x = [1.00486014 1.00965648], ||grad|| = 1.2011506358586848, Distance to solution: 0.010810574958239458\n",
      "Iteration 6: x = [1.00008351 1.00014421], ||grad|| = 0.04814265063775351, Distance to solution: 0.00016664385558154938\n",
      "Iteration 7: x = [1.00000038 1.00000075], ||grad|| = 0.01035404059954795, Distance to solution: 8.420582784010321e-07\n",
      "Iteration 8: x = [1. 1.], ||grad|| = 3.7843401551172776e-06, Distance to solution: 1.0455400474096064e-12\n",
      "\n",
      "Summary - Run 1:\n",
      "Number of iterations: 9\n",
      "Final iterate x_k: [1. 1.]\n",
      "The size ||\n",
      "abla f(x_k)||: 0.0\n",
      "The distance to the solution: 0.0\n",
      "\n",
      "Run 2:\n",
      "Iteration 1: x = [-1.1752809   1.38067416], ||grad|| = 232.86768775422664, Distance to solution: 2.208338697540567\n",
      "Iteration 2: x = [-0.91343237  0.76526556], ||grad|| = 4.639426214066757, Distance to solution: 1.9277768816864183\n",
      "Iteration 3: x = [-0.78430893  0.59846763], ||grad|| = 32.188727358206386, Distance to solution: 1.8289304508565836\n",
      "Iteration 4: x = [-0.56554344  0.26416883], ||grad|| = 9.409933652774024, Distance to solution: 1.7298479086023508\n",
      "Iteration 5: x = [-0.43652341  0.17390652], ||grad|| = 19.267478008840097, Distance to solution: 1.6571149480415304\n",
      "Iteration 6: x = [-0.24058742  0.01267462], ||grad|| = 6.669921132307837, Distance to solution: 1.5855183853655974\n",
      "Iteration 7: x = [-0.11704185 -0.00156471], ||grad|| = 11.332343047335005, Distance to solution: 1.5003047592240202\n",
      "Iteration 8: x = [ 0.0637983  -0.03388206], ||grad|| = 4.244248948524616, Distance to solution: 1.3947708514373585\n",
      "Iteration 9: x = [0.17277991 0.01797591], ||grad|| = 7.644085178593253, Distance to solution: 1.2840032731737314\n",
      "Iteration 10: x = [0.33357253 0.08133187], ||grad|| = 2.51741957219163, Distance to solution: 1.1349346700444298\n",
      "Iteration 11: x = [0.42894331 0.17489678], ||grad|| = 6.55275560485548, Distance to solution: 1.0034445994180548\n",
      "Iteration 12: x = [0.57661377 0.30821197], ||grad|| = 1.8666320389522555, Distance to solution: 0.8110650845582666\n",
      "Iteration 13: x = [0.64893441 0.41588559], ||grad|| = 6.792593703677128, Distance to solution: 0.6814959255453117\n",
      "Iteration 14: x = [0.76150917 0.56542445], ||grad|| = 1.2344735736726293, Distance to solution: 0.4957154312670934\n",
      "Iteration 15: x = [0.82274933 0.6731661 ], ||grad|| = 4.88174124290802, Distance to solution: 0.3718039839014387\n",
      "Iteration 16: x = [0.9139031  0.82653483], ||grad|| = 1.156092387385501, Distance to solution: 0.19365650667081238\n",
      "Iteration 17: x = [0.94536196 0.89271958], ||grad|| = 3.468523117485387, Distance to solution: 0.12039271127101636\n",
      "Iteration 18: x = [0.98641123 0.97122311], ||grad|| = 0.3307267351623792, Distance to solution: 0.031823954015424386\n",
      "Iteration 19: x = [0.99642653 0.99276551], ||grad|| = 0.7650291268412384, Distance to solution: 0.008068921383572793\n",
      "Iteration 20: x = [0.99992972 0.99984718], ||grad|| = 0.03847597584052272, Distance to solution: 0.00016820908693584993\n",
      "Iteration 21: x = [0.99999983 0.99999965], ||grad|| = 0.005362719779474921, Distance to solution: 3.8917202652069283e-07\n",
      "Iteration 22: x = [1. 1.], ||grad|| = 1.8964477642984673e-06, Distance to solution: 4.0486691962495454e-13\n",
      "\n",
      "Summary - Run 2:\n",
      "Number of iterations: 23\n",
      "Final iterate x_k: [1. 1.]\n",
      "The size ||\n",
      "abla f(x_k)||: 0.0\n",
      "The distance to the solution: 0.0\n",
      "\n",
      "Run 3:\n",
      "Iteration 1: x = [1.22151166 0.9691091 ], ||grad|| = 164.3099510072351, Distance to solution: 0.22365523308583468\n",
      "Iteration 2: x = [1.21941394 1.48696595], ||grad|| = 276.5198530522295, Distance to solution: 0.5341145157964874\n",
      "Iteration 3: x = [1.12504648 1.25682187], ||grad|| = 0.44097513581815684, Distance to solution: 0.28564680207823073\n",
      "Iteration 4: x = [1.08009071 1.16457492], ||grad|| = 4.616352929025593, Distance to solution: 0.18302848773035651\n",
      "Iteration 5: x = [1.02305434 1.04338705], ||grad|| = 1.1095785284009265, Distance to solution: 0.04913184824030126\n",
      "Iteration 6: x = [1.00908734 1.01806219], ||grad|| = 1.5233053027994239, Distance to solution: 0.020219357593693366\n",
      "Iteration 7: x = [1.00034123 1.00060609], ||grad|| = 0.10447320707846415, Distance to solution: 0.000695545338257463\n",
      "Iteration 8: x = [1.00000514 1.00001017], ||grad|| = 0.03483048215305222, Distance to solution: 1.1396570997463349e-05\n",
      "Iteration 9: x = [1. 1.], ||grad|| = 5.989112363108352e-05, Distance to solution: 2.3638872591673786e-10\n",
      "\n",
      "Summary - Run 3:\n",
      "Number of iterations: 10\n",
      "Final iterate x_k: [1. 1.]\n",
      "The size ||\n",
      "abla f(x_k)||: 0.0\n",
      "The distance to the solution: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import line_search\n",
    "\n",
    "# rosenbrock function\n",
    "def rosenbrock(x):\n",
    "    return 100*(x[1] - x[0]**2)**2 + (1 - x[0])**2\n",
    "\n",
    "def rosenbrock_gradient(x):\n",
    "    return np.array([\n",
    "        -400*x[0]*(x[1] - x[0]**2) - 2*(1 - x[0]),\n",
    "        200*(x[1] - x[0]**2)\n",
    "    ])\n",
    "\n",
    "def rosenbrock_hessian(x):\n",
    "    return np.array([\n",
    "        [1200*x[0]**2 - 400*x[1] + 2, -400*x[0]],\n",
    "        [-400*x[0], 200]\n",
    "    ])\n",
    "\n",
    "def backtracking_line_search(func, grad, x, pk, alpha=0.5, beta=0.9):\n",
    "    t = 1.0\n",
    "    while func(x + t * pk) > func(x) + alpha * t * np.dot(grad, pk):\n",
    "        t *= beta\n",
    "    return t\n",
    "\n",
    "# modified newton method with line search and eigenvalue modification\n",
    "def modified_newton_eigen(x0, max_iter=1000, tol=1e-6):\n",
    "    x = np.array(x0)\n",
    "    for k in range(max_iter):\n",
    "        grad = rosenbrock_gradient(x)\n",
    "        hessian = rosenbrock_hessian(x)\n",
    "        \n",
    "        eigvals, eigvecs = np.linalg.eig(hessian)\n",
    "        \n",
    "        min_eigval = np.min(eigvals)\n",
    "        if min_eigval <= 0:\n",
    "            hessian += np.eye(len(x)) * (-min_eigval + 1e-6)\n",
    "        \n",
    "        # Compute search direction\n",
    "        pk = -np.linalg.solve(hessian, grad)\n",
    "        \n",
    "        alpha_k = backtracking_line_search(rosenbrock, grad, x, pk)\n",
    "        if alpha_k is None:\n",
    "            break\n",
    "        \n",
    "        x += alpha_k * pk\n",
    "        \n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            break\n",
    "        \n",
    "        print(f\"Iteration {k+1}: x = {x}, ||grad|| = {np.linalg.norm(grad)}, Distance to solution: {np.linalg.norm(x - np.array([1, 1]))}\")\n",
    "\n",
    "    return x, k+1\n",
    "\n",
    "# Starting points\n",
    "initial_points = [(1.2, 1.2), (-1.2, 1), (0.2, 0.8)]\n",
    "\n",
    "print(\"Task: Implementing modified Newton method with eigenvalue modification\\n\")\n",
    "\n",
    "for i, point in enumerate(initial_points):\n",
    "    print(f\"Run {i+1}:\")\n",
    "    x_opt, iterations = modified_newton_eigen(point)\n",
    "    print(f\"\\nSummary - Run {i+1}:\")\n",
    "    print(f\"Number of iterations: {iterations}\")\n",
    "    print(f\"Final iterate x_k: {x_opt}\")\n",
    "    print(f\"The size ||\\nabla f(x_k)||: {np.linalg.norm(rosenbrock_gradient(x_opt))}\")\n",
    "    print(f\"The distance to the solution: {np.linalg.norm(x_opt - np.array([1, 1]))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Newton Hessian</h1>\n",
    "<h3>Other Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Implementing modified Newton method with eigenvalue modification\n",
      "\n",
      "For the new function:\n",
      "Run 1:\n",
      "\n",
      "Summary - Run 1:\n",
      "Number of iterations: 1\n",
      "Final iterate x_k: [-0.2  1.2]\n",
      "The size ||\n",
      "abla f(x_k)||: 22.38190206394443\n",
      "The distance to the solution: 1.2165525060596438\n",
      "\n",
      "Run 2:\n",
      "\n",
      "Summary - Run 2:\n",
      "Number of iterations: 1\n",
      "Final iterate x_k: [3.8 0.1]\n",
      "The size ||\n",
      "abla f(x_k)||: 329.3131861131589\n",
      "The distance to the solution: 2.9410882339705484\n",
      "\n",
      "Run 3:\n",
      "\n",
      "Summary - Run 3:\n",
      "Number of iterations: 1\n",
      "Final iterate x_k: [1.9 0.6]\n",
      "The size ||\n",
      "abla f(x_k)||: 1500.0192055920484\n",
      "The distance to the solution: 0.9848857801796104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func_new(x):\n",
    "    return 150 * (x[0] * x[1])**2 + (0.5 * x[0] + 2 * x[1] - 2)**2\n",
    "\n",
    "def gradient_new(x):\n",
    "    return np.array([\n",
    "        600 * x[0] * (x[0] * x[1])**2 + 0.5 * (0.5 * x[0] + 2 * x[1] - 2),\n",
    "        300 * x[1] * (x[0] * x[1])**2 + 2 * (0.5 * x[0] + 2 * x[1] - 2)\n",
    "    ])\n",
    "\n",
    "def hessian_new(x):\n",
    "    return np.array([\n",
    "        [1200 * x[1]**2 + 1800 * x[0]**2 * x[1]**2 + 0.25, 600 * x[0] * x[1] + 600 * x[0]**3 * x[1] - 1],\n",
    "        [600 * x[0] * x[1] + 600 * x[0]**3 * x[1] - 1, 300 * x[0]**2 * x[1]**2 + 4]\n",
    "    ])\n",
    "\n",
    "def backtracking_line_search(func, grad, x, pk, alpha=0.5, beta=0.9):\n",
    "    t = 1.0\n",
    "    while func(x + t * pk) > func(x) + alpha * t * np.dot(grad, pk):\n",
    "        t *= beta\n",
    "        if t < 1e-8:\n",
    "            return None  # Line search failed\n",
    "    return t\n",
    "\n",
    "# Implementing modified NM with eigenvalue modification for both functions\n",
    "def modified_newton_eigen_both(func, gradient, hessian, x0, max_iter=1000, tol=1e-6):\n",
    "    x = np.array(x0)\n",
    "    for k in range(max_iter):\n",
    "        grad = gradient(x)\n",
    "        hess = hessian(x)\n",
    "        \n",
    "        eigvals, eigvecs = np.linalg.eig(hess)\n",
    "        \n",
    "        min_eigval = np.min(eigvals)\n",
    "        if min_eigval <= 0:\n",
    "            hess += np.eye(len(x)) * (-min_eigval + 1e-6)\n",
    "        \n",
    "        pk = -np.linalg.solve(hess, grad)\n",
    "        \n",
    "        alpha_k = backtracking_line_search(func, grad, x, pk)\n",
    "        if alpha_k is None:\n",
    "            break  # Line search failed\n",
    "        \n",
    "        x += alpha_k * pk\n",
    "        \n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            break\n",
    "        \n",
    "    return x, k+1\n",
    "\n",
    "# Starting points\n",
    "initial_points = [(-0.2, 1.2), (3.8, 0.1), (1.9, 0.6)]\n",
    "\n",
    "print(\"Task: Implementing modified Newton method with eigenvalue modification\\n\")\n",
    "\n",
    "print(\"For the new function:\")\n",
    "for i, point in enumerate(initial_points):\n",
    "    print(f\"Run {i+1}:\")\n",
    "    x_opt, iterations = modified_newton_eigen_both(func_new, gradient_new, hessian_new, point)\n",
    "    print(f\"\\nSummary - Run {i+1}:\")\n",
    "    print(f\"Number of iterations: {iterations}\")\n",
    "    print(f\"Final iterate x_k: {x_opt}\")\n",
    "    print(f\"The size ||\\nabla f(x_k)||: {np.linalg.norm(gradient_new(x_opt))}\")\n",
    "    print(f\"The distance to the solution: {np.linalg.norm(x_opt - np.array([1, 1]))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
